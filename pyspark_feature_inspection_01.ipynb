{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcb9c85-4901-4622-bd4b-83d2eb7adc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a spark session\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(\"local[*]\").\\\n",
    "                                     appName(\"spark_on_docker\").\\\n",
    "                                     getOrCreate()\n",
    "\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1529366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "author SparkByExamples.com\n",
    "\"\"\"\n",
    "\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8ff718",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "                    .appName('SparkByExamples.com') \\\n",
    "                    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ff381e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+------+------+\n",
      "|firstname|lastname|gender|salary|\n",
      "+---------+--------+------+------+\n",
      "|    James|   Smith|     M|  3000|\n",
      "|     Anna|    Rose|     F|  4100|\n",
      "|  Robert2|Williams|     M|  null|\n",
      "|   Robert|Williams|     M|  6200|\n",
      "+---------+--------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [('James','Smith','M',3000),\n",
    "  ('Anna','Rose','F',4100),\n",
    "  ('Robert2','Williams','M',None), \n",
    "  ('Robert','Williams','M',6200), \n",
    "]\n",
    "\n",
    "columns = [\"firstname\",\"lastname\",\"gender\",\"salary\"]\n",
    "df = spark.createDataFrame(data=data, schema = columns)\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d4dd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'salary1' not in df.columns:\n",
    "    print(\"aa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390f5691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new constanct column\n",
    "from pyspark.sql.functions import lit\n",
    "df.withColumn(\"bonus_percent\", lit(0.3)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5bcd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add column from existing column\n",
    "df.withColumn(\"bonus_amount\", df.salary*0.3).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986521e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add column by concatinating existing columns\n",
    "from pyspark.sql.functions import concat_ws\n",
    "df.withColumn(\"name\", concat_ws(\",\",\"firstname\",'lastname')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603cc148",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add current date\n",
    "from pyspark.sql.functions import current_date\n",
    "df.withColumn(\"current_date\", current_date()).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8901bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75413c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import current_date\n",
    "\n",
    "df.withColumn(\"current_date\", current_date()).\\\n",
    "     withColumn(\"grade\", \\\n",
    "          when((df.salary < 4000), lit(\"A\")).\\\n",
    "          when((df.salary >= 4000) & (df.salary <= 5000), lit(\"B\")).\\\n",
    "          otherwise(lit(\"C\"))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e1f664",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.catalog.dropTempView(\"df_view\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6573a089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ★ \"when\" function\n",
    "from pyspark.sql.functions import when\n",
    "df.withColumn(\"grade\", \\\n",
    "   when((df.salary < 4000), lit(\"A\")) \\\n",
    "     .when((df.salary >= 4000) & (df.salary <= 5000), lit(\"B\")).otherwise(lit(\"C\"))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310c4572",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"df_view\")\n",
    "spark.sql(\"select * from df_view\").\\\n",
    "     withColumn(\"current_date\", current_date()).\\\n",
    "     withColumn(\"grade\", \\\n",
    "          when((df.salary < 4000), lit(\"A\")).\\\n",
    "          when((df.salary >= 4000) & (df.salary <= 5000), lit(\"B\")).\\\n",
    "          otherwise(lit(\"C\"))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f63c9a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NULL check \n",
    "df = df.filter(df.salary.isNotNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3599fa96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+------+------+-----+\n",
      "|firstname|lastname|gender|salary|grade|\n",
      "+---------+--------+------+------+-----+\n",
      "|    James|   Smith|     M|  3000|    A|\n",
      "|     Anna|    Rose|     F|  4100|    B|\n",
      "|   Robert|Williams|     M|  6200|    C|\n",
      "+---------+--------+------+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ★ \"when\" function to UDF \n",
    "# CASE 1 \n",
    "\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "def salaryToGrade(value):\n",
    "   if   value < 4000 : return 'A'\n",
    "   elif value >= 4000 and value <= 5000 : return 'B'\n",
    "   else: return 'C'\n",
    "\n",
    "udfsalaryToGrade = udf(salaryToGrade, StringType())\n",
    "df_with_grade = df.withColumn(\"grade\", udfsalaryToGrade(\"salary\"))\n",
    "\n",
    "df_with_grade.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e13cad74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+------+------+------------+-----+\n",
      "|firstname|lastname|gender|salary|current_date|grade|\n",
      "+---------+--------+------+------+------------+-----+\n",
      "|    James|   Smith|     M|  3000|  2022-03-14|    A|\n",
      "|     Anna|    Rose|     F|  4100|  2022-03-14|    B|\n",
      "|   Robert|Williams|     M|  6200|  2022-03-14|    C|\n",
      "+---------+--------+------+------+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ★ \"when\" function to UDF \n",
    "# CASE 2 \n",
    "\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import current_date\n",
    "\n",
    "def salaryToGrade(value):\n",
    "   if   value < 4000 : return 'A'\n",
    "   elif value >= 4000 and value <= 5000 : return 'B'\n",
    "   else: return 'C'\n",
    "\n",
    "udfsalaryToGrade = udf(salaryToGrade, StringType())\n",
    "# df_with_grade = df.withColumn(\"grade\", udfsalaryToGrade(\"salary\"))\n",
    "\n",
    "\n",
    "df.createOrReplaceTempView(\"df_view\")\n",
    "spark.sql(\"select * from df_view\").\\\n",
    "     withColumn(\"current_date\", current_date()).\\\n",
    "     withColumn(\"grade\", udfsalaryToGrade(\"salary\")).show()\n",
    "\n",
    "\n",
    "# df_with_grade.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4b6239",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a27d08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add column using select\n",
    "df.select(\"firstname\",\"salary\", lit(0.3).alias(\"bonus\")).show()\n",
    "df.select(\"firstname\",\"salary\", lit(df.salary * 0.3).alias(\"bonus_amount\")).show()\n",
    "df.select(\"firstname\",\"salary\", current_date().alias(\"today_date\")).show()\n",
    "\n",
    "#Add columns using SQL\n",
    "df.createOrReplaceTempView(\"PER\")\n",
    "spark.sql(\"select firstname,salary, '0.3' as bonus from PER\").show()\n",
    "spark.sql(\"select firstname,salary, salary * 0.3 as bonus_amount from PER\").show()\n",
    "spark.sql(\"select firstname,salary, current_date() as today_date from PER\").show()\n",
    "spark.sql(\"select firstname,salary, \" +\n",
    "          \"case salary when salary < 4000 then 'A' \"+\n",
    "          \"else 'B' END as grade from PER\").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
