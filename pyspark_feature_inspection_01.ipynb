{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adcb9c85-4901-4622-bd4b-83d2eb7adc51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/spark-3.2.0-bin-hadoop3.2/jars/spark-unsafe_2.12-3.2.0.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/03/14 02:31:58 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "#create a spark session\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(\"local[*]\").\\\n",
    "                                     appName(\"spark_on_docker\").\\\n",
    "                                     getOrCreate()\n",
    "\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1529366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "author SparkByExamples.com\n",
    "\"\"\"\n",
    "\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c8ff718",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+------+------+\n",
      "|firstname|lastname|gender|salary|\n",
      "+---------+--------+------+------+\n",
      "|    James|   Smith|     M|  3000|\n",
      "|     Anna|    Rose|     F|  4100|\n",
      "|   Robert|Williams|     M|  6200|\n",
      "+---------+--------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "                    .appName('SparkByExamples.com') \\\n",
    "                    .getOrCreate()\n",
    "\n",
    "data = [('James','Smith','M',3000),\n",
    "  ('Anna','Rose','F',4100),\n",
    "  ('Robert','Williams','M',6200), \n",
    "]\n",
    "\n",
    "columns = [\"firstname\",\"lastname\",\"gender\",\"salary\"]\n",
    "df = spark.createDataFrame(data=data, schema = columns)\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7d4dd14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aa\n"
     ]
    }
   ],
   "source": [
    "if 'salary1' not in df.columns:\n",
    "    print(\"aa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "390f5691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+------+------+-------------+\n",
      "|firstname|lastname|gender|salary|bonus_percent|\n",
      "+---------+--------+------+------+-------------+\n",
      "|    James|   Smith|     M|  3000|          0.3|\n",
      "|     Anna|    Rose|     F|  4100|          0.3|\n",
      "|   Robert|Williams|     M|  6200|          0.3|\n",
      "+---------+--------+------+------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add new constanct column\n",
    "from pyspark.sql.functions import lit\n",
    "df.withColumn(\"bonus_percent\", lit(0.3)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f5bcd1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+------+------+------------+\n",
      "|firstname|lastname|gender|salary|bonus_amount|\n",
      "+---------+--------+------+------+------------+\n",
      "|    James|   Smith|     M|  3000|       900.0|\n",
      "|     Anna|    Rose|     F|  4100|      1230.0|\n",
      "|   Robert|Williams|     M|  6200|      1860.0|\n",
      "+---------+--------+------+------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Add column from existing column\n",
    "df.withColumn(\"bonus_amount\", df.salary*0.3).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "986521e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+------+------+---------------+\n",
      "|firstname|lastname|gender|salary|           name|\n",
      "+---------+--------+------+------+---------------+\n",
      "|    James|   Smith|     M|  3000|    James,Smith|\n",
      "|     Anna|    Rose|     F|  4100|      Anna,Rose|\n",
      "|   Robert|Williams|     M|  6200|Robert,Williams|\n",
      "+---------+--------+------+------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Add column by concatinating existing columns\n",
    "from pyspark.sql.functions import concat_ws\n",
    "df.withColumn(\"name\", concat_ws(\",\",\"firstname\",'lastname')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "603cc148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+------+------+------------+\n",
      "|firstname|lastname|gender|salary|current_date|\n",
      "+---------+--------+------+------+------------+\n",
      "|    James|   Smith|     M|  3000|  2022-03-14|\n",
      "|     Anna|    Rose|     F|  4100|  2022-03-14|\n",
      "|   Robert|Williams|     M|  6200|  2022-03-14|\n",
      "+---------+--------+------+------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Add current date\n",
    "from pyspark.sql.functions import current_date\n",
    "df.withColumn(\"current_date\", current_date()).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a8901bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- firstname: string (nullable = true)\n",
      " |-- lastname: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "75413c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+------+------+------------+-----+\n",
      "|firstname|lastname|gender|salary|current_date|grade|\n",
      "+---------+--------+------+------+------------+-----+\n",
      "|    James|   Smith|     M|  3000|  2022-03-14|    A|\n",
      "|     Anna|    Rose|     F|  4100|  2022-03-14|    B|\n",
      "|   Robert|Williams|     M|  6200|  2022-03-14|    C|\n",
      "+---------+--------+------+------+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import current_date\n",
    "\n",
    "df.withColumn(\"current_date\", current_date()).\\\n",
    "     withColumn(\"grade\", \\\n",
    "          when((df.salary < 4000), lit(\"A\")).\\\n",
    "          when((df.salary >= 4000) & (df.salary <= 5000), lit(\"B\")).\\\n",
    "          otherwise(lit(\"C\"))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "408122cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+------+------+------------+-----+\n",
      "|firstname|lastname|gender|salary|current_date|grade|\n",
      "+---------+--------+------+------+------------+-----+\n",
      "|    James|   Smith|     M|  3000|  2022-03-14|    A|\n",
      "|     Anna|    Rose|     F|  4100|  2022-03-14|    B|\n",
      "|   Robert|Williams|     M|  6200|  2022-03-14|    C|\n",
      "+---------+--------+------+------+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.createOrReplaceTempView(\"df_view\")\n",
    "spark.sql(\"select * from df_view\").\\\n",
    "     withColumn(\"current_date\", current_date()).\\\n",
    "     withColumn(\"grade\", \\\n",
    "          when((df.salary < 4000), lit(\"A\")).\\\n",
    "          when((df.salary >= 4000) & (df.salary <= 5000), lit(\"B\")).\\\n",
    "          otherwise(lit(\"C\"))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "34e1f664",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.catalog.dropTempView(\"df_view\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6573a089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+------+------+-----+\n",
      "|firstname|lastname|gender|salary|grade|\n",
      "+---------+--------+------+------+-----+\n",
      "|    James|   Smith|     M|  3000|    A|\n",
      "|     Anna|    Rose|     F|  4100|    B|\n",
      "|   Robert|Williams|     M|  6200|    C|\n",
      "+---------+--------+------+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# â˜… \"when\" function\n",
    "from pyspark.sql.functions import when\n",
    "df.withColumn(\"grade\", \\\n",
    "   when((df.salary < 4000), lit(\"A\")) \\\n",
    "     .when((df.salary >= 4000) & (df.salary <= 5000), lit(\"B\")).otherwise(lit(\"C\"))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a27d08d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+------+------+\n",
      "|firstname|lastname|gender|salary|\n",
      "+---------+--------+------+------+\n",
      "|    James|   Smith|     M|  3000|\n",
      "|     Anna|    Rose|     F|  4100|\n",
      "|   Robert|Williams|     M|  6200|\n",
      "+---------+--------+------+------+\n",
      "\n",
      "aa\n",
      "+---------+--------+------+------+-------------+\n",
      "|firstname|lastname|gender|salary|bonus_percent|\n",
      "+---------+--------+------+------+-------------+\n",
      "|    James|   Smith|     M|  3000|          0.3|\n",
      "|     Anna|    Rose|     F|  4100|          0.3|\n",
      "|   Robert|Williams|     M|  6200|          0.3|\n",
      "+---------+--------+------+------+-------------+\n",
      "\n",
      "+---------+--------+------+------+------------+\n",
      "|firstname|lastname|gender|salary|bonus_amount|\n",
      "+---------+--------+------+------+------------+\n",
      "|    James|   Smith|     M|  3000|       900.0|\n",
      "|     Anna|    Rose|     F|  4100|      1230.0|\n",
      "|   Robert|Williams|     M|  6200|      1860.0|\n",
      "+---------+--------+------+------+------------+\n",
      "\n",
      "+---------+--------+------+------+---------------+\n",
      "|firstname|lastname|gender|salary|           name|\n",
      "+---------+--------+------+------+---------------+\n",
      "|    James|   Smith|     M|  3000|    James,Smith|\n",
      "|     Anna|    Rose|     F|  4100|      Anna,Rose|\n",
      "|   Robert|Williams|     M|  6200|Robert,Williams|\n",
      "+---------+--------+------+------+---------------+\n",
      "\n",
      "+---------+--------+------+------+------------+\n",
      "|firstname|lastname|gender|salary|current_date|\n",
      "+---------+--------+------+------+------------+\n",
      "|    James|   Smith|     M|  3000|  2022-03-13|\n",
      "|     Anna|    Rose|     F|  4100|  2022-03-13|\n",
      "|   Robert|Williams|     M|  6200|  2022-03-13|\n",
      "+---------+--------+------+------+------------+\n",
      "\n",
      "+---------+--------+------+------+-----+\n",
      "|firstname|lastname|gender|salary|grade|\n",
      "+---------+--------+------+------+-----+\n",
      "|    James|   Smith|     M|  3000|    A|\n",
      "|     Anna|    Rose|     F|  4100|    B|\n",
      "|   Robert|Williams|     M|  6200|    C|\n",
      "+---------+--------+------+------+-----+\n",
      "\n",
      "+---------+------+-----+\n",
      "|firstname|salary|bonus|\n",
      "+---------+------+-----+\n",
      "|    James|  3000|  0.3|\n",
      "|     Anna|  4100|  0.3|\n",
      "|   Robert|  6200|  0.3|\n",
      "+---------+------+-----+\n",
      "\n",
      "+---------+------+------------+\n",
      "|firstname|salary|bonus_amount|\n",
      "+---------+------+------------+\n",
      "|    James|  3000|       900.0|\n",
      "|     Anna|  4100|      1230.0|\n",
      "|   Robert|  6200|      1860.0|\n",
      "+---------+------+------------+\n",
      "\n",
      "+---------+------+----------+\n",
      "|firstname|salary|today_date|\n",
      "+---------+------+----------+\n",
      "|    James|  3000|2022-03-13|\n",
      "|     Anna|  4100|2022-03-13|\n",
      "|   Robert|  6200|2022-03-13|\n",
      "+---------+------+----------+\n",
      "\n",
      "+---------+------+-----+\n",
      "|firstname|salary|bonus|\n",
      "+---------+------+-----+\n",
      "|    James|  3000|  0.3|\n",
      "|     Anna|  4100|  0.3|\n",
      "|   Robert|  6200|  0.3|\n",
      "+---------+------+-----+\n",
      "\n",
      "+---------+------+------------+\n",
      "|firstname|salary|bonus_amount|\n",
      "+---------+------+------------+\n",
      "|    James|  3000|       900.0|\n",
      "|     Anna|  4100|      1230.0|\n",
      "|   Robert|  6200|      1860.0|\n",
      "+---------+------+------------+\n",
      "\n",
      "+---------+------+----------+\n",
      "|firstname|salary|today_date|\n",
      "+---------+------+----------+\n",
      "|    James|  3000|2022-03-13|\n",
      "|     Anna|  4100|2022-03-13|\n",
      "|   Robert|  6200|2022-03-13|\n",
      "+---------+------+----------+\n",
      "\n",
      "+---------+------+-----+\n",
      "|firstname|salary|grade|\n",
      "+---------+------+-----+\n",
      "|    James|  3000|    B|\n",
      "|     Anna|  4100|    B|\n",
      "|   Robert|  6200|    B|\n",
      "+---------+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add column using select\n",
    "df.select(\"firstname\",\"salary\", lit(0.3).alias(\"bonus\")).show()\n",
    "df.select(\"firstname\",\"salary\", lit(df.salary * 0.3).alias(\"bonus_amount\")).show()\n",
    "df.select(\"firstname\",\"salary\", current_date().alias(\"today_date\")).show()\n",
    "\n",
    "#Add columns using SQL\n",
    "df.createOrReplaceTempView(\"PER\")\n",
    "spark.sql(\"select firstname,salary, '0.3' as bonus from PER\").show()\n",
    "spark.sql(\"select firstname,salary, salary * 0.3 as bonus_amount from PER\").show()\n",
    "spark.sql(\"select firstname,salary, current_date() as today_date from PER\").show()\n",
    "spark.sql(\"select firstname,salary, \" +\n",
    "          \"case salary when salary < 4000 then 'A' \"+\n",
    "          \"else 'B' END as grade from PER\").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
